7.26
发现Platt-SMO对setosa与versicolor进行二分类时表现良好（参数设置C=0.9; tol=0.001; maxIter=20; 正确率0.95，即有一个分类错误）
涉及virginica的二分类时测试集有多于一半错误（参数设置C=0.8; tol=0.001; maxIter=20; 正确率0.45）

三分类时：参数设置: C=0.0001; tol=0.1; maxIter=40；正确率0.87

7.27
引入高斯核函数之后，涉及virginica的二分类时测试准确度大幅提高
发现virginica与setosa的测试中kTup越小，测试准确率越高
（参数设置C=0.9; tol=0.001; maxIter=20; kTup=0.5;正确率0.95，即有一个分类错误）

三分类时
kTup=('rbf',2.6);C=0.8;tol=0.001;maxIter=40
kTup1=('rbf',1.3);C1=0.9;tol1=0.001;maxIter1=20
预测正确率大概为0.77(0.73~0.9，不知道为什么会出现0.9)
sklearn的测试正确率为0.867（C=2,gamma=10）
Platt-SMO具有随机性，sklearn的SVM不具有随机性

8.31
换了一台电脑，原来是Linux现在是windows，数据集路径变了，数据集格式变了，原代码不能跑了（???）。
重构了一下svm的代码，但是我不是很能理解我之前照书打的Platt-SMO.py为什么可以走
（我看不懂代码写的是什么，我怀疑我打错了很多地方，但是它确实可以走，???）
SVM.py是参照Platt给出的SMO伪代码写的，数据结构和部分逻辑参照周志华机器学习中给出py代码
发现对b更新不起作用，w是可以正确分类的，但是偏移量b很有问题
（我不知道为什么）
所以我把对b的更新删了（反正其实用不上），最后再求b

训练集为每一类前40个，测试集为每一类后10个

下面为分类器训练结果：

    不采用核函数时，3分类器正确率在0.6~1.0 之间浮动，分类模型习惯把versicolor与virginica分类错
    参数配置为：
        C = 0.8
        tol = 0.01
        maxIter = 20 或 30
        kTup = ['lin', 0.6]

    采用gauss核函数(kTup=0.6)时，20次测试中3分类器正确率在0.6~1.0 之间浮动

    0.6~0.7: 2 times;
    0.7~0.8: 4 times;
    0.8~0.9: 3 times;
    0.9~1.0: 10 times;
    1.0: 1 times;

    分类模型习惯把versicolor与virginica分类错
    参数:
        C = 0.8
        tol = 0.01
        maxIter = 30
        kTup = ['rbf', 0.6]

    采用gauss核函数(kTup=0.5)时，20次测试中3分类器正确率在0.6~1.0 之间浮动

    0.6~0.7: 1 times;
    0.7~0.8: 3 times;
    0.8~0.9: 1 times;
    0.9~1.0: 10 times;
    1.0: 5  times;

    忘记看分类模型的习惯错误了
    参数:
        C = 0.8
        tol = 0.01
        maxIter = 30
        kTup = ['rbf', 0.5]

9.8
减少训练集和测试集的规模
60k太大了...减少到600
先把参数测出来。

9.10
训练集减少到 600，测试集减少到 200,只涉及 0 和 1 的分类使用线性分类器
测了4次正确率全是 1 不测了

线性分类器
参数设置：
    C = 0.8,
    tol = 0.01,
    maxIter = 30,
    kTup=['lin', 0.8]

1&2 1&3 1&4 1&5 1&6
    2&3 2&4 2&5 2&6
        3&4 3&5 3&6
            4&5 4&6
                5&6

            12
          13
        14
       15 45

9.12
初步完成了SVM.py
着重检查一下predict的while循环

9.16
trainSize = 50*10
testSize = 10*10
0.702 correct
highest
0.7, 0.01, 20, ['lin', 0.8]

error matrix
[[ 0  0  2  0  0  0  0  0  2  0]
 [ 0  0  0  0  0  0  0  4  2  0]
 [ 1  1  0  0  0  1  0  3  7  0]
 [ 0  0  1  0  0  7  0  2 10  0]
 [ 0  0  0  2  0  0  5  8  6  4]
 [ 0  1  1  5  0  0  1  4 24  0]
 [ 1  0  2  0  0  0  0  0  0  0]
 [ 0  0  0  0  1  0  0  0  1  1]
 [ 1  0  1  1  0  0  2  4  0  0]
 [ 0  0  0  4  1  0  0 14 11  0]]

try trAdaBoost