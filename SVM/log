7.26
发现Platt-SMO对setosa与versicolor进行二分类时表现良好（参数设置C=0.9; tol=0.001; maxIter=20; 正确率0.95，即有一个分类错误）
涉及virginica的二分类时测试集有多于一半错误（参数设置C=0.8; tol=0.001; maxIter=20; 正确率0.45）

三分类时：参数设置: C=0.0001; tol=0.1; maxIter=40；正确率0.87

7.27
引入高斯核函数之后，涉及virginica的二分类时测试准确度大幅提高
发现virginica与setosa的测试中kTup越小，测试准确率越高
（参数设置C=0.9; tol=0.001; maxIter=20; kTup=0.5;正确率0.95，即有一个分类错误）

三分类时
kTup=('rbf',2.6);C=0.8;tol=0.001;maxIter=40
kTup1=('rbf',1.3);C1=0.9;tol1=0.001;maxIter1=20
预测正确率大概为0.77(0.73~0.9，不知道为什么会出现0.9)
sklearn的测试正确率为0.867（C=2,gamma=10）
Platt-SMO具有随机性，sklearn的SVM不具有随机性

8.31
换了一台电脑，原来是Linux现在是windows，数据集路径变了，数据集格式变了，原代码不能跑了（???）。
重构了一下svm的代码，但是我不是很能理解我之前照书打的Platt-SMO.py为什么可以走
（我看不懂代码写的是什么，我怀疑我打错了很多地方，但是它确实可以走，???）
SVM.py是参照Platt给出的SMO伪代码写的，数据结构和部分逻辑参照周志华机器学习中给出py代码
发现对b更新不起作用，w是可以正确分类的，但是偏移量b很有问题
（我不知道为什么）
所以我把对b的更新删了（反正其实用不上），最后再求b

训练集为每一类前40个，测试集为每一类后10个

下面为分类器训练结果：

    不采用核函数时，3分类器正确率在0.6~1.0 之间浮动，分类模型习惯把versicolor与virginica分类错
    参数配置为：
        C = 0.8
        tol = 0.01
        maxIter = 20 或 30
        kTup = ['lin', 0.6]

    采用gauss核函数(kTup=0.6)时，20次测试中3分类器正确率在0.6~1.0 之间浮动

    0.6~0.7: 2 times;
    0.7~0.8: 4 times;
    0.8~0.9: 3 times;
    0.9~1.0:10 times;
    1.0: 1 times;

    分类模型习惯把versicolor与virginica分类错
    参数:
        C = 0.8
        tol = 0.01
        maxIter = 30
        kTup = ['rbf', 0.6]

    采用gauss核函数(kTup=0.5)时，20次测试中3分类器正确率在0.6~1.0 之间浮动

    0.6~0.7: 1 times;
    0.7~0.8: 3 times;
    0.8~0.9: 1 times;
    0.9~1.0:10 times;
    1.0:5  times;

    忘记看分类模型的习惯错误了
    参数:
        C = 0.8
        tol = 0.01
        maxIter = 30
        kTup = ['rbf', 0.5]
